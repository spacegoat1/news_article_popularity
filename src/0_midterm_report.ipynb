{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40cd4651-6a3c-4a52-a86c-b72f71f96537",
   "metadata": {},
   "source": [
    "<center><h2>Prediction of Online News Popularity</h2></center>\n",
    "    \n",
    "<center><h3>Midterm Report for DATA1030 Fall 2021 at Brown University</h3></center>\n",
    "    \n",
    "<center><h3>Supervised by Dr. Andras Zsom</h3></center>\n",
    "    \n",
    "<center><a href=\"https://github.com/spacegoat1/news_article_popularity\">Project on Github</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba15f8-944e-49a9-a202-8fd8744f9bc1",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Over the past couple of decades, with online news platforms increasingly winning out over physical newspapers, media organizations are relying more and more on analytics and machine learning to understand their reader base, moderate interactions and analyze which content is more likely to generate traffic. The pandemic has only accelerated this effort, with advertising revenues falling and platforms having the rely on subscriptions to generate revenues. \n",
    "\n",
    "In this context, being able to predict what content is likely to resonate with readers is very important not only for media organizations, but also for activists and political organizations, and as highlighted in recent news, tech companies as well. Such analyses can use information which is available after the fact,  which can make the prediction task easier, or only use features accessible before publication. This approach yields lower predition scores, but can be significantly more useful as a signal to a content provider if it can indicate where to focus efforts in order to optimize content, or to a platform that publishes such content so that it can focus its moderation efforts on articles which are likely to go viral. \n",
    "\n",
    "This projects attempts to explore the performance of various machine learning models in predicting the likelihood of a news article becoming popular, as measured by how often it is shared on social media. The dataset used comes from the UCI Machine Learning Repository, covering a set of articles published on the online platform Mashable over a period of 2 years, from January 7 2013 to January 7 2015. The data contain 39,644 records, each corresponding to an article published on Mashable. Each records has 61 attributes - 2 of which are non-predictive, and 1 of which is the target variable (no. of shares) and the remaining 58 are predictive features. While the number of shares is a continuous variable, in this project a threshold is set, above which an article is labelled 'popular', thus converting the task into a classification problem. \n",
    "\n",
    "This project uses the paper published by Kelwin Fernandes, Paulo Cortez and Pedro Vinagre in **TBD** as its primary reference, which introduced and published the associated dataset. The authors of the article focus on predicting classifying article popularity before publication, and then make build a system to make recommendations to optimize the likelihood of popularity. They used 47 features and applied various models, eventually settling on a Random Forest classifier with an accuracy of 67% as the best model. Further work by  **Zhang et. al.** expands upon this by using PCA for feature selection, but their difference in thresholds and classification (they use low/medium/high popularity tiers) is not comparable to the original paper. **Ren et. al.** use Mutual Information and Fisher Criterion for feature selection, and improve the accuracy of the random forest classifier to 69%. This project attempts to replicate their findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9b87a-c8b9-47d6-a782-5c048b282b08",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b77cb2-c25e-414f-b43c-81f96d6c91aa",
   "metadata": {},
   "source": [
    "## 3. Methods\n",
    "\n",
    "### 3.1 Data Splitting\n",
    "The dataset consists of records of online articles published by Mashable. Each row corresponds to a single article. There are a total of 39,644 articles. \n",
    "\n",
    "The target variable is 'popular' - this is a binary variable where 0 corresponds to not-popular and 1 corresponds to popular. This variable is derived from the 'shares' variable present in the original dataset. Shares is the number of shares for a given article, and we set a threshold = 1400, above which an article is considered popular. \n",
    "\n",
    "The features list various characteristics about the articles, including some NLP based metrics, the number of tokens in the title, in the content, the number of images and videos, the topic and the day of the week on which the article was published. There are 58 features. \n",
    "\n",
    "Since there is no group structure or time-series structure to the data, the data can be considered IID. \n",
    "\n",
    "The point of this project was to be able to predict how popular an article would be *before publication*, and make recommendations to increase popularity. \n",
    "\n",
    "Each of the feature variables is available to us prior to publication in a production environment, so we can safely split the dataset into the standard train:validation:test split. Here, a split of 70:20:10, which gives us 27751, 7929, 3964 articles for the train, validation and test sets respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e99a62-7725-4ab9-9c1e-8606d0cbed9c",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing\n",
    "\n",
    "On the continuous features, the MinMaxEncoder for features relating to polarity, Latent Dirichlet Allocation (LDA) features, polarity related features and no. of tokens in title, average token length and number of keywords. None of the other continuous features are well bounded and exhibit fat tailed distributions. Hence, they are encoded with a StandardScaler.  \n",
    "\n",
    "From the categorical features, I use OneHotEncoder on data_channel, since that tells us what the topic of the article is, and it is not possibly to order topics. Similarly, I use OneHot encoding on the is_weekend feature. \n",
    "\n",
    "The last remaining categorical feature is the day_of_week feature, for which I use the OrdinalEncoder since the days of the week occur in a sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7d25e-f8c6-4149-b1a2-5098eef4f125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
